{
 "metadata": {
  "name": "",
  "signature": "sha256:545b75198e613bbf0147b429bbf737019b08451aa2b62160eeb5e0a626cfc2ca"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import sklearn as sk\n",
      "print 'pandas version: ',pd.__version__\n",
      "print 'numpy version:',np.__version__\n",
      "print 'sklearn version:',sk.__version__"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "pandas version:  0.13.1\n",
        "numpy version: 1.8.1\n",
        "sklearn version: 0.14.1\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys,os\n",
      "cwd=os.getcwd()\n",
      "path=cwd.split('/')\n",
      "home_dir='/'.join(path[:-2])\n",
      "print home_dir\n",
      "sys.path.append(home_dir+'/utils')\n",
      "from find_waiting_flow import *\n",
      "from AWS_keypair_management import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/ubuntu/UCSD_BigData\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_dir=home_dir+'/data/weather'\n",
      "!ls $data_dir"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ALL.head.csv\t  ghcnd-stations_buffered.txt  SAMPLE_TMAX.csv\r\n",
        "data-source.txt   ghcnd-stations.txt\t       SAMPLE_TMAX.csv.old.gz\r\n",
        "ghcnd-readme.txt  ghcnd-version.txt\r\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ls *.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "coding.py  map-year-temp.py  mr_word_freq_count.py  Statistics.py\r\n",
        "ECatch.py  mr_weather.py     reduce-year-temp.py\r\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%writefile ECatch.py\n",
      "import traceback\n",
      "from functools import wraps\n",
      "from sys import stderr\n",
      "\"\"\"this decorator is intended for decorating a function, not a\n",
      "generator.  Therefor to use it in the context of mrjob, the generator\n",
      "should call a function that handles a single input records, and that\n",
      "function should be decorated.\n",
      "\n",
      "The reason is that if a generator throws an exception it exits and\n",
      "cannot process any more records.\n",
      "\n",
      "\"\"\"\n",
      "def ECatch(func):\n",
      "    print type(func)\n",
      "    f_name=func.__name__\n",
      "    @wraps(func)\n",
      "    def inner(self,*args,**kwargs):\n",
      "        try:\n",
      "            self.increment_counter(self.__class__.__name__,'total in '+f_name,1)\n",
      "            return func(self,*args,**kwargs)\n",
      "        except Exception as e:\n",
      "            self.increment_counter(self.__class__.__name__,'errors in '+f_name,1)\n",
      "            stderr.write('Error:')\n",
      "            stderr.write(str(e))\n",
      "            traceback.print_exc(file=stderr)\n",
      "            stderr.write('Arguments were %s, %s\\n'%(args,kwargs))\n",
      "            pass\n",
      "    return inner        \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting ECatch.py\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from ECatch import *\n",
      "class C:\n",
      "    def increment_counter(self,a,b,n):\n",
      "        print 'increment counter(',a,b,n,')'\n",
      "    @ECatch\n",
      "    def Z(self,list):\n",
      "        print list\n",
      "        print sum(list)\n",
      "        return sum(list)\n",
      "CC=C()\n",
      "print CC.Z([1,'a',2])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<type 'function'>\n",
        "increment counter( C total in Z 1 )\n",
        "[1, 'a', 2]\n",
        "increment counter( C errors in Z 1 )\n",
        "None\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Error:cannot perform reduce with flexible typeTraceback (most recent call last):\n",
        "  File \"ECatch.py\", line 20, in inner\n",
        "    return func(self,*args,**kwargs)\n",
        "  File \"<ipython-input-10-f45e96cc9b76>\", line 8, in Z\n",
        "    print sum(list)\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/numpy/core/fromnumeric.py\", line 1709, in sum\n",
        "    out=out, keepdims=keepdims)\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/numpy/core/_methods.py\", line 25, in _sum\n",
        "    out=out, keepdims=keepdims)\n",
        "TypeError: cannot perform reduce with flexible type\n",
        "Arguments were ([1, 'a', 2],), {}\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "CC.__class__.__name__"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "'C'"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%writefile Stations_Statistics.py\n",
      "#!/usr/bin/python\n",
      "\"\"\"\n",
      "collect the statistics for each station.\n",
      "\"\"\"\n",
      "import re,pickle,base64,zlib\n",
      "from sys import stderr\n",
      "import sys\n",
      "\n",
      "sys.path.append('/usr/lib/python2.6/dist-packages') # a hack because anaconda made mrjob unreachable\n",
      "from mrjob.job import MRJob\n",
      "from mrjob.protocol import *\n",
      "\n",
      "import traceback\n",
      "from functools import wraps\n",
      "from sys import stderr\n",
      "\n",
      "\"\"\"this decorator is intended for decorating a function, not a\n",
      "generator.  Therefor to use it in the context of mrjob, the generator\n",
      "should call a function that handles a single input records, and that\n",
      "function should be decorated.\n",
      "\n",
      "The reason is that if a generator throws an exception it exits and\n",
      "cannot process any more records.\n",
      "\n",
      "\"\"\"\n",
      "def ECatch(func):\n",
      "    f_name=func.__name__\n",
      "    @wraps(func)\n",
      "    def inner(self,*args,**kwargs):\n",
      "        try:\n",
      "            self.increment_counter(self.__class__.__name__,'total in '+f_name,1)\n",
      "            return func(self,*args,**kwargs)\n",
      "        except Exception as e:\n",
      "            self.increment_counter(self.__class__.__name__,'errors in '+f_name,1)\n",
      "            stderr.write('Error:')\n",
      "            stderr.write(str(e))\n",
      "            traceback.print_exc(file=stderr)\n",
      "            stderr.write('Arguments were %s, %s\\n'%(args,kwargs))\n",
      "            pass\n",
      "    return inner        \n",
      "\n",
      "\"\"\"\n",
      "Functions for encoding and decoding arbitrary object into ascii \n",
      "so that they can be passed through the hadoop streaming interface.\n",
      "\"\"\"\n",
      "\n",
      "def loads(eVal):\n",
      "    \"\"\" Decode a string into a value \"\"\"\n",
      "    return pickle.loads(zlib.decompress(base64.b64decode(eVal)))\n",
      "\n",
      "def dumps(Value):\n",
      "    \"\"\" Encode a value as a string \"\"\"\n",
      "    return base64.b64encode(zlib.compress(pickle.dumps(Value),9))\n",
      "\n",
      "class MRWeather(MRJob):\n",
      "\n",
      "    @ECatch\n",
      "    def map_one(self,line):\n",
      "        return line.split(',')\n",
      "    \n",
      "    def mapper(self, _, line):\n",
      "        elements=self.map_one(line)\n",
      "        yield(elements[0],elements[1:])\n",
      "            \n",
      "    def check_integrity(self,meas,year,length):\n",
      "        year=int(year)\n",
      "        if year<1000 or year > 2014: return False\n",
      "        if meas=='': return False\n",
      "        if length != 367: return False\n",
      "        return True\n",
      "    \n",
      "    @ECatch\n",
      "    def reduce_one(self,S,vector):\n",
      "        meas=vector[0]\n",
      "        year=vector[1]\n",
      "        length=len(vector)\n",
      "        number_defined=sum([e!='' for e in vector[2:]])\n",
      "        assert self.check_integrity(meas,year,length)==True\n",
      "        S[(meas,int(year))]=number_defined\n",
      "        \n",
      "    def reducer(self, station, vectors):\n",
      "        S={}\n",
      "        for vector in vectors:\n",
      "            self.reduce_one(S,vector)\n",
      "        yield(station,dumps(S))\n",
      "                              \n",
      "if __name__ == '__main__':\n",
      "    MRWeather.run()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting Stations_Statistics.py\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Running job inline"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!head -1 $data_dir/ALL.head.csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ASN00054128,DAPR,1969,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\r\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python Stations_Statistics.py --help"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Usage: Stations_Statistics.py [options] [input files]\r\n",
        "\r\n",
        "Options:\r\n",
        "  --help                show this message and exit\r\n",
        "  --help-emr            show EMR-related options\r\n",
        "  --help-hadoop         show Hadoop-related options\r\n",
        "  --help-runner         show runner-related options\r\n",
        "\r\n",
        "  Running specific parts of the job:\r\n",
        "    --mapper            run a mapper\r\n",
        "    --combiner          run a combiner\r\n",
        "    --reducer           run a reducer\r\n",
        "    --step-num=STEP_NUM\r\n",
        "                        which step to execute (default is 0)\r\n",
        "    --steps             print the mappers, combiners, and reducers that this\r\n",
        "                        job defines\r\n",
        "\r\n",
        "  Protocols:\r\n",
        "    --strict-protocols  If something violates an input/output protocol then\r\n",
        "                        raise an exception\r\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ls $data_dir"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ALL.head.csv\t  ghcnd-stations_buffered.txt  SAMPLE_TMAX.csv\r\n",
        "data-source.txt   ghcnd-stations.txt\t       SAMPLE_TMAX.csv.old.gz\r\n",
        "ghcnd-readme.txt  ghcnd-version.txt\r\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python Stations_Statistics.py $data_dir/ALL.head.csv > StationStatistics.pkl"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "using configs in /home/ubuntu/.mrjob.conf\r\n",
        "creating tmp directory /tmp/Stations_Statistics.ubuntu.20140520.030723.262974\r\n",
        "writing to /tmp/Stations_Statistics.ubuntu.20140520.030723.262974/step-0-mapper_part-00000\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Counters from step 1:\r\n",
        "  MRWeather:\r\n",
        "    total in map_one: 999\r\n",
        "writing to /tmp/Stations_Statistics.ubuntu.20140520.030723.262974/step-0-mapper-sorted\r\n",
        "> sort /tmp/Stations_Statistics.ubuntu.20140520.030723.262974/step-0-mapper_part-00000\r\n",
        "writing to /tmp/Stations_Statistics.ubuntu.20140520.030723.262974/step-0-reducer_part-00000\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Counters from step 1:\r\n",
        "  MRWeather:\r\n",
        "    total in map_one: 999\r\n",
        "    total in reduce_one: 999\r\n",
        "Moving /tmp/Stations_Statistics.ubuntu.20140520.030723.262974/step-0-reducer_part-00000 -> /tmp/Stations_Statistics.ubuntu.20140520.030723.262974/output/part-00000\r\n",
        "Streaming final output from /tmp/Stations_Statistics.ubuntu.20140520.030723.262974/output\r\n",
        "removing tmp directory /tmp/Stations_Statistics.ubuntu.20140520.030723.262974\r\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python Stations_Statistics.py -r emr --emr-job-flow-id $job_flow_id $data_dir/ALL.head.csv > StationStatistics.pkl"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## managing AWS Credentials ##\n",
      "The full details on how to get the credentials set up is given here: https://docs.google.com/document/d/1xDUy4ZI2yr1eCCRQ4ynWHsctbEb7ySHrSynBu0bxupU/edit?usp=sharing"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!echo $EC2_VAULT"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/Users/yoavfreund/BigData/Vault\r\n"
       ]
      }
     ],
     "prompt_number": 157
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "Creds_file=os.environ['EC2_VAULT']+'/Creds.pkl'\n",
      "Creds= pickle.load(open(Creds_file,'rb'))\n",
      "print Creds.keys()\n",
      "print Creds['mrjob'].keys()\n",
      "pair=Creds['mrjob']\n",
      "key_id=pair['key_id']\n",
      "secret_key=pair['secret_key']\n",
      "ID=pair['ID']\n",
      "print ID,key_id"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['launcher', 'admin', 'mrjob']\n",
        "['key_id', 'secret_key', 's3_logs', 'ID', 's3_scratch']\n",
        "Yoav_Student AKIAJ3SIH7HZ53WL4YMA\n"
       ]
      }
     ],
     "prompt_number": 139
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Checking for an available job flow###\n",
      "Before submitting your job for execution you need to find out which job flows are active and waiting. THe following cell will do that for you. If there is a waiting cluster, it will put it's ID into the variable `job_flow_id`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "job_flow_id=find_waiting_flow(key_id,secret_key)\n",
      "job_flow_id"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<boto.emr.emrobject.JobFlow object at 0x102af1f10> no_script.yoavfreund.20140516.040032.370095 j-262J0JTFJIRLO WAITING\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 168,
       "text": [
        "u'j-262J0JTFJIRLO'"
       ]
      }
     ],
     "prompt_number": 168
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Setting up the mrjob configuration file ###\n",
      "The last step before submitting the job is to insert the credentials into the file `/home/ubuntu/UCSD_BigData/utils/mrjob.conf.template` and put the result in the default location for the mrjob configuration file which is: `/home/ubuntu/.mrjob.conf`\n",
      "this is done by the following line. If the return value is `True` you are good to go. If it is `False` something went wrong and you should get an error message.\n",
      "\n",
      "The template file should work as is. However, feel free to change and add fields to this configuration file to make it your own.\n",
      "\n",
      "This step needs to be done just one time. Redone only when starting a new EC2 instance or if the credentials changed.\n",
      "It is better to do it in an interactive shell, rather than in a notebook. Here it is done in the notebook for demonstration purpose."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%cd /home/ubuntu/UCSD_BigData/utils/\n",
      "!python Make.mrjob.conf.py\n",
      "%cd ../notebooks/weather.mapreduce/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[Errno 2] No such file or directory: '/home/ubuntu/UCSD_BigData/utils/'\n",
        "/Users/yoavfreund/academic.papers/Courses/BigDataAnalytics/UCSD_BigData/notebooks/weather.mapreduce\n",
        "python: can't open file 'Make.mrjob.conf.py': [Errno 2] No such file or directory\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[Errno 2] No such file or directory: '../notebooks/weather.mapreduce/'\n",
        "/Users/yoavfreund/academic.papers/Courses/BigDataAnalytics/UCSD_BigData/notebooks/weather.mapreduce\n"
       ]
      }
     ],
     "prompt_number": 141
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Assuming the steps up to here were all successful, you should be ready to launch your mrjob job. There is no need to change anything\n",
      "in the following line."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python Stations_Statistics.py -r emr --emr-job-flow-id  $job_flow_id  hdfs:/weather/weather.csv > Statistics.pkl"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "using configs in /home/ubuntu/.mrjob.conf\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "creating tmp directory /tmp/Stations_Statistics.ubuntu.20140520.030743.165054\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "reading from STDIN\r\n"
       ]
      }
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    }
   ],
   "metadata": {}
  }
 ]
}